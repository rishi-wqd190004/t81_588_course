{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector to Sequence --> Image Captioning\n",
    "- Sequence to Vector --> Sentiment Analysis\n",
    "- Sequence to Sequence --> Language translation\n",
    "\n",
    "Some important hyperparameters:\n",
    "- num_layers = 4 --> How many encoder and decoder layers are there\n",
    "- d_model = 128 --> Size of embedding vector or use pre-loaded embeddings from Word2vec or GloVe\n",
    "- dff = 512 --> Specifies size of dense feedforward layers\n",
    "- num_heads = 8 --> Sets the number of attention layers head\n",
    "- droupout_rate = 0.1 --> Percentage to combat overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inside Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenize the input English sentence --> Helps to understand suffix and prefix independently\n",
    "    Each Token become a numeric index which transformer uses to look up the vector\n",
    "    - Index 0 = Pad\n",
    "    - Index 1 = Unknown\n",
    "    - Index 2 = Start\n",
    "    - Index 3 = End\n",
    "\n",
    "2. Positional encoding: Adds the slopes of a sine and cosine wave to the token vectors to encode position\n",
    "3. Multi-Head Self attention: Each vector has key(k), value(v) and query(q)\n",
    "    attention score = dot product of query and key\n",
    "    multiple attention heads are used to capture different aspects of relationships between tokens\n",
    "4. Scaled dot-product attention: \n",
    "    Attention scores are scaled by square root of dimension of key to prevent the dot products from becoming too large\n",
    "5. Feedforward NN:\n",
    "    Each attention head's o/p is passed throught a FFN --> dense layer with ReLU\n",
    "6. Layer normalization and Residual Connections\n",
    "7. Position wise FNN\n",
    "8. Add and Normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
