{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_dir = '/Users/rishinigam/t81_588_course/deep_learning/Faster_RCNN/models_pretrained'\n",
    "\n",
    "os.makedirs(model_weights_dir, exist_ok=True)\n",
    "torch.hub.set_dir(model_weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = f'../dataset_DL/BCCD_Dataset/BCCD/JPEGImages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv('../dataset_DL/BCCD_Dataset/full.csv')\n",
    "train = pd.read_csv('../dataset_DL/BCCD_Dataset/processed_csv/train.csv')\n",
    "val = pd.read_csv('../dataset_DL/BCCD_Dataset/processed_csv/val.csv')\n",
    "test = pd.read_csv('../dataset_DL/BCCD_Dataset/processed_csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('../dataset_DL/BCCD_Dataset/BCCD/JPEGImages/BloodImage_00301.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['img_name'].nunique(), val['img_name'].nunique(), test['img_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cell_type'].value_counts(), val['cell_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img with detection (BB)\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "img = plt.imread('../dataset_DL/BCCD_Dataset/BCCD/JPEGImages/BloodImage_00301.jpg')\n",
    "plt.imshow(img)\n",
    "\n",
    "for _, row in train[train.img_name == 'BloodImage_00301.jpg'].iterrows():\n",
    "    x_min = row.x_min\n",
    "    x_max = row.x_max\n",
    "    y_min = row.y_min\n",
    "    y_max = row.y_max\n",
    "\n",
    "    w = x_max - x_min\n",
    "    h = y_max - y_min\n",
    "\n",
    "    if row.cell_type == 'RBC':\n",
    "        edgecolor = 'r'\n",
    "        ax.annotate('RBC', xy=(x_max-40,y_min+20))\n",
    "    elif row.cell_type == 'WBC':\n",
    "        edgecolor = 'b'\n",
    "        ax.annotate('WBC', xy=(x_max-40,y_min+20))  \n",
    "    elif row.cell_type == 'Platelets':\n",
    "        edgecolor = 'g'\n",
    "        ax.annotate('Platelets', xy=(x_max-40,y_min+20)) \n",
    "\n",
    "    # adding BB\n",
    "    rect = patches.Rectangle((x_min, y_min), w, h, edgecolor=edgecolor, facecolor='none')\n",
    "\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling and data prepping\n",
    "- Will use pytorch dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir,label_mapping,  transforms=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.label_mapping = label_mapping\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get image and its annotations\n",
    "        img_name = self.annotations.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "\n",
    "        img = read_image(img_path).float() # check the float conversion\n",
    "\n",
    "        # pick annotation for that particular file\n",
    "        img_annotations = self.annotations[self.annotations['img_name'] == img_name]\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(img_annotations)):\n",
    "            x_min = img_annotations.iloc[i,2]\n",
    "            x_max = img_annotations.iloc[i,3]\n",
    "            y_min = img_annotations.iloc[i,4]\n",
    "            y_max = img_annotations.iloc[i,5]\n",
    "            label = img_annotations.iloc[i,1]\n",
    "\n",
    "            if x_max > x_min and y_max > y_min:\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                labels.append(self.label_mapping[label])\n",
    "        \n",
    "        if len(boxes) == 0:\n",
    "            # Return empty target if no valid boxes\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        # converting to tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"RBC\": 1,\n",
    "    \"WBC\": 2,\n",
    "    \"Platelets\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Filter out None values from batch\n",
    "    batch = [b for b in batch if b[1] is not None]\n",
    "    imgs, targets = zip(*batch) if batch else ([], [])\n",
    "    \n",
    "    # Return images and targets\n",
    "    return list(imgs), list(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "train_dataset = CellDataset(csv_file='../dataset_DL/BCCD_Dataset/processed_csv/train.csv', root_dir=img_paths, label_mapping=label_mapping)\n",
    "val_dataset = CellDataset(csv_file='../dataset_DL/BCCD_Dataset/processed_csv/val.csv', root_dir=img_paths, label_mapping=label_mapping)\n",
    "test_dataset = CellDataset(csv_file='../dataset_DL/BCCD_Dataset/processed_csv/test.csv', root_dir=img_paths, label_mapping=label_mapping)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "def get_model(num_classes):\n",
    "    # loading model\n",
    "    backbone = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights=FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT)\n",
    "    backbone.out_channels = 2048\n",
    "\n",
    "    model = FasterRCNN(backbone, num_classes)\n",
    "    # replace classifer with a new one for the specific num of classes\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "num_classes = len(set(train_dataset.annotations['cell_type'])) + 1\n",
    "model = get_model(num_classes)\n",
    "model.to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for imgs, targets in train_loader:\n",
    "        if imgs is None or targets is None:\n",
    "            continue\n",
    "        imgs = list(img.to(mps_device) for img in imgs)\n",
    "        targets = [{k: v.to(mps_device) for k, v in t.items()} for t in targets]\n",
    "        print(targets)\n",
    "        # forward pass\n",
    "        loss_dict = model(imgs, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # Backpropogation\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += losses.item()\n",
    "    print(f'Epoch {epoch_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shuttle_feeder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
