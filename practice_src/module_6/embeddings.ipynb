{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layers in PyTorch\n",
    "- Allows to insert vectors in the place of word indexes.\n",
    "- As dimension expansion\n",
    "\n",
    "### Simple embedding layer\n",
    "- __num_embeddings__ - How large is the vocabulary? How many categories you encoding\n",
    "- __embedding_dim__ - How many number in the vecotr you to return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(num_embeddings=10, embedding_dim=4)\n",
    "optimizer = torch.optim.Adam(embedding_layer.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[[-0.6789,  1.1378,  0.9993,  1.0034],\n",
      "         [-0.9585,  1.9641,  0.8160,  1.4132]]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([1, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[1,2]], dtype=torch.long)\n",
    "pred = embedding_layer(input_tensor)\n",
    "\n",
    "print(input_tensor.shape)\n",
    "print(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6318,  0.4854, -0.4328, -1.6026],\n",
       "        [-0.6789,  1.1378,  0.9993,  1.0034],\n",
       "        [-0.9585,  1.9641,  0.8160,  1.4132],\n",
       "        [-0.1024,  1.0981,  0.1542,  1.0665],\n",
       "        [ 1.0539,  1.2050, -1.1417, -0.2653],\n",
       "        [ 0.7194,  0.4700, -0.2606, -0.7559],\n",
       "        [-0.3073, -0.4720,  0.2014, -0.7850],\n",
       "        [-1.0288,  0.5153, -0.7029, -0.8905],\n",
       "        [-0.4648,  0.4477, -2.1117,  0.4215],\n",
       "        [ 0.0648, -0.3432,  2.3571,  0.4730]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above values are just random values but in next part will see how to train these above values to generate something meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfering an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding lookup matrix\n",
    "embedding_lookup = torch.eye(3)\n",
    "\n",
    "embedding_layer = nn.Embedding(num_embeddings=3, embedding_dim=3)\n",
    "\n",
    "embedding_layer.weight.data = embedding_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0.],\n",
      "         [0., 1., 0.]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[0,1]], dtype=torch.long)\n",
    "pred = embedding_layer(input_tensor)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The given output shows that we provided the program with two rows from the one-hot encoding table. This encoding is a correct one-hot encoding for the values 0 and 1, where there are up to 3 unique values possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    'Never coming back!',\n",
    "    'Horrible service',\n",
    "    'Rude waitress',\n",
    "    'Cold food.',\n",
    "    'Horrible food!',\n",
    "    'Awesome',\n",
    "    'Awesome service!',\n",
    "    'Rocks!',\n",
    "    'poor work',\n",
    "    'Couldn\\'t have done better']\n",
    "\n",
    "# Define labels (1=negative, 0=positive)\n",
    "labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 2, 18,  8]), tensor([44, 19]), tensor([44, 34]), tensor([15, 37]), tensor([44, 27]), tensor([11]), tensor([11, 12]), tensor([35]), tensor([4, 7]), tensor([32,  6, 41, 26])]\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 50\n",
    "encoded_reviews = [torch.tensor([hash(word) % VOCAB_SIZE for word in review.split()]) for review in reviews]\n",
    "\n",
    "print(encoded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8091158445156410952\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(hash('Never'))\n",
    "print(hash('Never') % 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "- As the lengths are different --> path these reviews to 4 words and truncate words beyond the fourth word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 18,  8,  0],\n",
      "        [44, 19,  0,  0],\n",
      "        [44, 34,  0,  0],\n",
      "        [15, 37,  0,  0],\n",
      "        [44, 27,  0,  0],\n",
      "        [11,  0,  0,  0],\n",
      "        [11, 12,  0,  0],\n",
      "        [35,  0,  0,  0],\n",
      "        [ 4,  7,  0,  0],\n",
      "        [32,  6, 41, 26]])\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 4\n",
    "padded_reviews = pad_sequence(encoded_reviews, batch_first=True, padding_value=0).narrow(1,0,MAX_LENGTH)\n",
    "print(padded_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(VOCAB_SIZE, 8),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(8 * MAX_LENGTH, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(padded_reviews.long())\n",
    "    loss = criterion(outputs.squeeze(), torch.tensor(labels, dtype=torch.float))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Log-loss: 0.3765341341495514\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    outputs = model(padded_reviews.long())\n",
    "    predictions = (outputs > 0.5).float().squeeze()\n",
    "    accuracy = (predictions == torch.tensor(labels)).float().mean().item()\n",
    "    loss_value = criterion(outputs.squeeze(), torch.tensor(labels, dtype=torch.float)).item()\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Log-loss: {loss_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important things:\n",
    "- When asking a question to LLM keep in mind: framing, clarity and precision\n",
    "- Clarity\n",
    "- Specificity\n",
    "- Iteration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
